---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

withr::local_options(
  warnPartialMatchArgs = FALSE,
  warnPartialMatchDollar = FALSE,
  warnPartialMatchAttr = FALSE
)

library(bccamtrap)
library(dplyr)
library(sf)

set.seed(13)
```

# bccamtrap

<!-- badges: start -->
[![R-CMD-check](https://github.com/bcgov/bccamtrap/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/ateucher/bccamtrap/actions/workflows/R-CMD-check.yaml)
[![img](https://img.shields.io/badge/Lifecycle-Maturing-339999)](https://github.com/bcgov/repomountie/blob/master/doc/lifecycle-badges.md)
[![Codecov test coverage](https://codecov.io/gh/bcgov/bccamtrap/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bcgov/bccamtrap?branch=main)
<!-- badges: end -->

Functions for QA and validation of Camera Trap data

1. [Installation](#installation)
2. [Example Usage](#example-usage)
    i. [Project and station metadata](#project-and-station-metadata)
    ii. [Project Metadata: Field Form CSV files](#project-metadata-field-form-csv-files)
    iii. [Image data](#image-data)
    iv. [Built-in plotting functions](#built-in-plotting-functions)
    v. [Sampling sessions](#sampling-sessions)
    vi. [Analysis data](#analysis-data)
    vii. [Write Data to SPI template](#write-data-to-spi-template)
3. [Shiny](#bccamtrapp-shiny-app)
    

## Installation

You can install the development version of bccamtrap from [GitHub](https://github.com/) using 
the [devtools](https://devtools.r-lib.org/) package (you may need to install it first):

If don't have devtools installed, install it:

``` r
install.packages("devtools")
```

Then you can install the bccamtrap package:

```r
devtools::install_github("bcgov/bccamtrap")
```

## Example Usage

This package is being developed for camera trap studies in the West Coast Region, 
BC Ministry of Water, Land, and Resource Stewardship (WLRS).

The functions in this package currently assume your project and session-level data
are stored in a BC Government [Wildlife Data Submission Template](https://www2.gov.bc.ca/gov/content?id=DC67BCBF8B1E462889B854364364D2D1) for Camera Trap Data,
augmented with additional fields.

The image data is expected to be in multiple csv files, in one folder per project.
The csv files have been generated by reviewing the images in [TimeLapse](https://saul.cpsc.ucalgary.ca/timelapse/) software, using
the template `v20230518`.

**Note that example data has been obfuscated to protect the location of the projects.**

To begin, set the paths to the project metadata file, and the folder containing the
TimeLapse image files:

```{r}
#| eval: false
library(bccamtrap)

metadata_path <- "~/data/project-files/project_1_RISC_WCR_Database_Template_v20230518.xlsm"
data_path <- "~/data/wc-wlrs-cam-data/camera-data/project_1/"
```


```{r}
#| include: false

googledrive::drive_auth(path = Sys.getenv("GDRIVE_AUTH_TOKEN"))
drv <- googledrive::drive_get(id = "1EY559-jrhrkazFsJ8AoKH0OBewRfdsPq")

temp_dir <- withr::local_tempdir(
  pattern = "bccamtrap_readme"
)

zip_file <- googledrive::drive_download(
  drv,
  file.path(temp_dir, drv$name),
  overwrite = TRUE
)

temp_dir_1 <- tools::file_path_sans_ext(zip_file$local_path)
unzip(zip_file$local_path, exdir = dirname(temp_dir_1), overwrite = TRUE)

files <- list.files(temp_dir_1, full.names = TRUE)
merged_files <- grep("merged", files, value = TRUE)
file.remove(merged_files)
files <- setdiff(files, merged_files)

data_path <- temp_dir_1
metadata_path <- grep(".xls[xm]?$", files, value = TRUE)

# Dummy print methods to drop any sensitive info
print.sample_station_info <- function(x, ...) {
  x <- sf::st_drop_geometry(x) %>% 
    select(-contains(c("utm", "easting", "northing", "dd")))
  print(as_tibble(x))
}

print.image_data <- print.deployments <- print.camera_info <- print.sample_station_info
registerS3method("print", "sample_station_info", print.sample_station_info)
registerS3method("print", "camera_info", print.sample_station_info)
registerS3method("print", "deployments", print.deployments)
registerS3method("print", "image_data", print.deployments)

obfuscate_location <- function(x) {
  
  # Add random adjustment to coordinates of up to 500 Km
  x <- st_transform(x, 3005)
  st_geometry(x) <- st_geometry(x) + sample(-500000:500000, 2)
  
  # Move one point 40 km North so we get an outlier
  st_geometry(x)[[1]] <- st_geometry(x)[[1]] + c(40000, 0)
  st_crs(x) <- 3005
  x <- st_transform(x, 4326)
  x
}
```

### Project and station metadata

Read in project metadata from the SPI worksheet. There are functions to read
the relevant tabs:

#### Project Information

```{r}
proj <- read_project_info(metadata_path)
proj
```

#### Sample station information

Read the sample station information. This creates a spatial data frame of class
`"sf"`, from the [sf](https://r-spatial.github.io/sf/) package. This format allows
us to work with it as a regular data frame, but also do spatial things with it.


```{r}
#| eval: false
sample_stations <- read_sample_station_info(metadata_path)
sample_stations
```

```{r, obfuscate}
#| echo: false
sample_stations <- read_sample_station_info(metadata_path)
sample_stations$study_area_name <- "Test Project"

(sample_stations <- obfuscate_location(sample_stations))
```

Use the `qa_stations_spatial()` function to run some basic spatial validation
on the data - namely checking for spatial outliers:

```{r}
sample_stations <- qa_stations_spatial(sample_stations)
```

Use the `summary()` method for Sample Station Info for basic descriptive stats:

```{r}
summary(sample_stations)
```

Use the `map_stations()` function to create an interactive map the of the stations. This 
will show any potential outlying stations, indicating possible data errors:

```{r, map-stations}
map_stations(sample_stations)
```

#### Camera Information:

Read camera information using `read_camera_info()`:

```{r}
#| eval: false
camera_info <- read_camera_info(metadata_path)
camera_info
```

```{r}
#| echo: false
camera_info <- read_camera_info(metadata_path)
camera_info$study_area_name <- "Test Project"
camera_info
```

#### Camera Setup and Checks:

```{r}
#| eval: false
camera_setup_checks <- read_cam_setup_checks(metadata_path)
camera_setup_checks
```

```{r}
#| echo: false
camera_setup_checks <- read_cam_setup_checks(metadata_path)
camera_setup_checks$study_area_name <- "Test Project"
camera_setup_checks
```

#### Deployments

Rather than just looking at the raw camera setup and checks or stations, there is more utility in assembling sampling deployments by combining the sample station information and the camera setup and checks. Do this with the `make_deployments()` function.

```{r}
#| eval: false
deployments <- make_deployments(metadata_path)
deployments
```

```{r}
#| echo: false
deployments <- make_deployments(metadata_path)
deployments$study_area_name <- "Test Project"
(deployments <- obfuscate_location(deployments))
```

There is a handy `summary()` method for this as well:

```{r}
summary(deployments)
```

We can use the [mapview](https://r-spatial.github.io/mapview/) package to quickly visualize this, setting the `zcol` argument to the name of the column you'd like to colour the points by. Clicking on a point will give you the details of that deployment.

```{r, mapview-deployments}
library(mapview)
mapview(deployments, zcol = "sample_station_label")
```

### Project Metadata: Field Form CSV files

There are also two functions for reading in the different csv outputs from the field forms: Sample Stations, and Deployments:

```{r, sample-station-csv}
#| eval: false
sample_station_info <- read_sample_station_csv("path-to-sample-stations.csv")
```

```{r, deployments-csv}
#| eval: false
deployments <- read_deployments_csv("path-to-deployments.csv")
```

### Image data

We can read in an entire directory of image data from multiple csv files, as long
as they all follow the same TimeLapse template. Currently it is expected that
they follow the `v20230518` template.

```{r}
#| eval: false
image_data <- read_image_data(data_path)
image_data
```

```{r}
#| echo: false
image_data <- read_image_data(data_path)
image_data$study_area_name <- "Test Project"
image_data
```

Again, we can use the `summary()` method to get an overview of the image data.

```{r}
summary(image_data)
```

Use the `qa_deployment_images()` function to find deployment labels that are 
in the deployment data but not in the image data, and vice-versa. It is usually
likely that there will be deployment labels in the deployment data that are missing
from the image data if not all of the images have been processed yet. Deployment
labels that are present in the image data but not in the deployment data indicate
a potential problem.

```{r}
qa_deployment_images(deployments, image_data)
```

Use `merge_deployments_images()` to join the deployment metadata to the images:

```{r}
images_with_metadata <- merge_deployments_images(deployments, image_data)
images_with_metadata
```

#### Image Data QA

There are a number of common data quality issues that we can check for in the image
data itself, aside from those addressed above when reconciling deployments and images.

We can use the `qa_image_data()` function to detect the following problems:

* Check for blanks in key fields: study area, station label, deployment date,
 surveyor, trigger mode, temperature, episode
* Species detected with no count data
* Count data with no species
* Sum of individual count fields equals Total Count
* Multiple entries under same Episode number (indicating possible double entry)
* Ensure dates for timelapse images are continuous and in order.
* Snow data
   - No blanks unless lens obscured is `TRUE`
   - Look for snow depth outliers (e.g., 10, 10, 110, 10, 15, 20)
   
Run the `qa_image_data()` function:
   
```{r}
image_data_qa <- qa_image_data(image_data)
dim(image_data_qa)
```

We can see that this has identified `r nrow(image_data_qa)` records with potential problems.
This dataset has a number of fields starting with `QA_` which help us know which 
images we should have a closer look at. All of the original fields, plus any `QA_` 
fields that have at least one `TRUE` value are returned:

```{r}
# Print the names of the columns, just to see what we're working with
names(image_data_qa)
```

We can use functions from the [dplyr](https://dplyr.tidyverse.org) package to select and 
view just the QA columns. bccamtrap uses dplyr as a dependency, so it will already be installed 
on your system, though it does need to be loaded.

```{r}
library(dplyr)

select(image_data_qa, root_folder, file, starts_with("QA_"))
```

### Built-in plotting functions

There are several plotting functions available to help you visualize your data
and spot any potential problems. By default, all plots render as static images, 
but can be created as interactive plots by setting `interactive = TRUE`. Interactive
plots are not shown here as they don't render in the `README`.

#### Deployment plot

We can plot deployments to see that the start and ends of our deployments are 
as expected, and flag any "invalid" deployments (i.e., where we don't know the end 
time because a camera was stolen, bumped, ran out of batteries etc.). You can 
make static or interactive plots:

```{r, plot-deployments}
plot_deployments(deployments, date_breaks = "2 months")
# plot_deployments(deployments, interactive = TRUE, date_breaks = "2 months")
```

#### Snow depth plot

We can plot the recorded snow depths across deployments using the `plot_snow()`
function with our image data:

```{r, plot-snow}
plot_snow(image_data, date_breaks = "2 months")
# plot_snow(image_data, date_breaks = "2 months", interactive = TRUE)
```

#### Detection plot

We can also plot image timestamps over the deployment durations to alert us to 
potential time mismatches between the session data and image time labels. 
Mismatches could indicate wrong time settings on cameras, errors in deployment 
labels (as the below indicates), or any number of data entry errors.

```{r, plot-detections}
plot_deployment_detections(deployments, image_data, date_breaks = "2 months")
# plot_deployment_detections(deployments, image_data, interactive = TRUE, date_breaks = "2 months")
```

#### Daily detection patterns

We can plot the patterns of daily detections by species:

```{r, plot-diel}
plot_diel_activity(image_data)
# plot_diel_activity(image_data, interactive = TRUE)
```

### Sampling sessions

Define sampling sessions based on image data using the 
`make_sample_sessions()` function. This function will:

- Set sampling_start as deployment_start
- Notes dates of first and last photos of deployment
- Counts photos (total, and motion-detection)
- Determines if the sampling period is less than the deployment period
- Determines gaps in sampling period due to obscured lens
- Determines total length of sample period (last photo date - first photo date - number of days with lens obscured)

```{r}
#| eval: false
make_sample_sessions(image_data)
```

```{r}
#| echo: false
make_sample_sessions(image_data) %>% 
  select(-study_area_name, -sample_station_label)
```

You can set custom start and end dates for your sample session as well:

```{r}
#| eval: false
make_sample_sessions(
  image_data, 
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
)
```

```{r}
#| echo: false
make_sample_sessions(
  image_data, 
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
) %>% 
  select(-study_area_name, -sample_station_label)
```

### Analysis data

#### Relative Activity Index (RAI)

Calculate Relative Activity Index for sample sessions using `sample_rai()`. By default, it 
calculates RAI per species using the sample start and end dates in the data for each 
deployment:

```{r, sample-rai}
sample_rai(image_data)
```

You can set it to do a subset of species and/or deployment labels, and similar
to `make_sample_sessions()`, set custom session start and end dates:

```{r, sample-rai-2}
sample_rai(
  image_data, 
  species = "Roosevelt Elk", 
  deployment_label = c("19_2_20230605", "29_1_20230605"),
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
)
```

You can also calculate RAI across all deployments by setting `by_deployment = FALSE`:

```{r, sample-rai-3}
sample_rai(
  image_data, 
  species = "Roosevelt Elk", 
  by_deployment = FALSE,
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
)
```

We can compare total count and RAI across species:

```{r, sample-rai-4}
spp_comp <- sample_rai(
  image_data, 
  by_deployment = FALSE,
  by_species = TRUE,
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
)
spp_comp
```

Using the [ggplot2](https://ggplot2.tidyverse.org/) package, we can plot this:

```{r sample-rai4-plot}
library(ggplot2)

ggplot(spp_comp, aes(x = rai, y = species)) + 
  geom_point(colour = "darkgreen") + 
  geom_text(aes(label = total_count), nudge_x = 0.05, nudge_y = 0.1) +
  theme_classic() + 
  labs(title = "RAI of all species detected, across all deployments", 
       caption = "Numbers beside points represent total number of individuals detected",
       x = "Relative Activity Index", y = "Species")
```

We can group by deployment to compare across deployments:

```{r, sample-rai-5}
spp_comp_by_dep <- sample_rai(
  image_data, 
  by_deployment = TRUE,
  by_species = TRUE,
  sample_start_date = "2022-12-01", 
  sample_end_date = "2023-04-30"
)

ggplot(spp_comp_by_dep, aes(x = rai, y = species, colour = deployment_label)) + 
  geom_point() + 
  geom_text(aes(label = total_count), nudge_x = 0.01, nudge_y = 0.1) +
  theme_classic() + 
  labs(title = "RAI of all species detected, across all deployments", 
       caption = "Numbers beside points represent total number of individuals detected",
       x = "Relative Activity Index", y = "Species")
```

#### Relative Activity Index (RAI) over time

Use `rai_by_time()` to calculate RAI over a time window, optionally calculating
statistics using a moving window aggregation. You can calculate daily statistics, 
or aggregate by week, month, or year. By default, it calculates daily metrics, 
aggregating across deployments.

```{r, rai-by-time}
rai_by_time(image_data)
```

We can select a single species, and calculate daily rolling values. The default
window size is 7, but it can be changed with the `k` parameter.

```{r, rai-by-time2}
elk_roll_avg <- rai_by_time(
  image_data, 
  by = "date",
  species = "Roosevelt Elk",
  roll = TRUE
)
elk_roll_avg

ggplot(elk_roll_avg, aes(x = date, y = roll_rai)) + 
  geom_line(colour = "darkgreen") + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of Elk RAI", 
    x = "Date", 
    y = "7 day rolling average RAI"
  )
```

Since the data returned by `rai_by_time` also includes snow and temperature data, 
we can plot these, and then compare RAI to these environment variables:

```{r}
ggplot(elk_roll_avg, aes(x = date, y = roll_mean_max_snow)) + 
  geom_line(colour = "darkblue") + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of average maximum snow index across sites", 
    x = "Date", 
    y = "7 day rolling average of maximum snow index"
  )
```

We can change the way snow measurements are aggregated across sites when `by_deployment = FALSE`. By default it uses `max`, but we can set it to any aggregation function, like `mean`:

```{r}
elk_roll_avg <- rai_by_time(
  image_data, 
  by = "date",
  species = "Roosevelt Elk",
  roll = TRUE,
  snow_agg = "mean"
)

ggplot(elk_roll_avg, aes(x = date, y = roll_mean_mean_snow)) + 
  geom_line(colour = "darkblue") + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of mean snow index across sites", 
    x = "Date", 
    y = "7 day rolling average of mean snow index"
  )
```

And we can compare Elk activity to snow levels:

```{r}
ggplot(elk_roll_avg, aes(x = roll_mean_mean_snow, y = roll_rai, colour = mean_temperature)) + 
  geom_point() + 
  scale_colour_viridis_c(option = "inferno") + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of Elk RAI compared to Snow Index", 
    x = "7 day rolling average of mean Snow Index across sites", 
    y = "7 day rolling average RAI",
    colour = "Temperature"
  )
```

And temperature:

```{r}
ggplot(elk_roll_avg, aes(x = roll_mean_temp, y = roll_rai)) + 
  geom_point() + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of Elk RAI compared to Temperature", 
    x = "7 day rolling average of mean temperature across sites", 
    y = "7 day rolling average RAI"
  )
```

We can compare raw counts vs snow depth across deployments. Note that for daily
counts (`by = "date"`) when `by_deployment = TRUE`, the "trap_days" in each row is equal to 
1, so RAI is a bit meaningless and we can just compare raw counts:

```{r}
elk_rai_by_dep <- rai_by_time(
  image_data, 
  by = "date",
  species = "Roosevelt Elk",
  by_deployment = TRUE
)

ggplot(elk_rai_by_dep, aes(x = snow_index, y = total_count, colour = deployment_label)) + 
  facet_wrap(vars(deployment_label)) + 
  geom_point()
```

If we want to compare the RAI of two species, we can specify them in the `species`
argument, and colour our plot by species (if we left the `species` argument blank
we would get a line per species, but that looks visually very busy).

```{r, rai-by-time3}
all_spp_roll_avg <- rai_by_time(
  image_data, 
  by = "date",
  species = c("Roosevelt Elk", "Cougar"),
  by_species = TRUE,
  roll = TRUE
  )

ggplot(all_spp_roll_avg, aes(x = date, y = roll_rai, colour = species)) + 
  geom_line() + 
  theme_classic() + 
  labs(
    title = "Rolling seven day average of RAI for Cougar and Elk", 
    x = "Date", 
    y = "7 day rolling average RAI"
  )
```

Here we use it to compare the total monthly activity by all species among
all deployments:

```{r, rai-by-time4}
total_rai_by_month <- rai_by_time(
  image_data, 
  by = "month",
  by_species = FALSE,
  by_deployment = TRUE
  )

ggplot(total_rai_by_month, aes(x = month, y = rai, fill = deployment_label)) + 
  geom_col(position = "dodge") + 
  theme_classic() + 
  labs(
    title = "Monthly RAI of all species", 
    x = "Month", 
    y = "RAI"
  )
```

### Write Data to SPI template

bccamtrap also has functionality to write out data to a SPI template for submission.

Use `fill_spi_template()` to write all of the data to a SPI template, 
filling in just the default required fields. This will fill in all of the tabs 
except for the Project Info sheet which you must fill in manually.

```{r}
#| eval: false
fill_spi_template(
  sample_stations,
  camera_info, 
  camera_setup_checks,
  image_data,
  file = "~/Desktop/SPI_output.xlsx"
)
```

If you want more control, such as adding data to other fields in the SPI 
template, use `write_to_spi_sheet()`.

If you want to write to an existing file, specify the same file name in both the
`file` and the `template` parameters. To write columns other than the 
default columns, specify paired column names in the form `` `Destination Column` = data_column``. If the left-hand side is a syntactically valid name it can be provided as-is, but if it has spaces in it it must be wrapped in backticks or quotes.

```{r}
#| eval: false
write_to_spi_sheet(
  sample_stations,
  file = "~/Desktop/SPI_output.xlsx",
  `Number of Cameras` = number_of_cameras,
  template = "~/Desktop/SPI_output.xlsx"
)
```

#### Writing to SPI template using field form data

To write data imported from field form data, you must use the `fill_spi_template_ff()`
function, passing in both the `sample_station_info` and `deployments`, as well as the `image_data`. 

If you want to only write to the metadata tabs and not the Sequence Image Data, 
you can leave the `image_data` argument as `NULL`, and write to the file another 
time with `write_to_spi_sheet()`.

```{r}
#| eval: false
sample_station_info <- read_sample_station_csv("path-to-sample-stations.csv")
deployments <- read_deployments_csv("path-to-deployments.csv")

fill_spi_template_ff(
  sample_stations,
  deployments,
  image_data,
  file = "~/Desktop/SPI_output_from_ff.xlsx"
)
```

### bccamtrapp() Shiny App

The package contains a Shiny App for interactive use of most of the package's
functionality.

Run the app with:

```r
library(bccamtrap)
bccamtrapp()
```

Data is loaded, and exported, via inputs on the left-hand side. You can use metadata 
from a SPI worksheet, or from a combination of csv-based field forms (sample stations and deployments).

Loading image data is done by selecting all image files in the dialogue or drag-and-drop.

The various tabs are useful for data summaries, QA, and generation of analysis data:

- "Project Metadata" and "Deployments" rely only on having input the metadata files. 

- "QA Deployments vs Images" requires both metadata and image data files, and makes
sure that they are compatible.

- "Image Data QA", "Sample Sessions", and "Analysis Data" all require the image data
to be loaded, but don't require the metadata.

To export to a SPI template for submission, you need to have loaded metadata and 
image data. This will write only the required fields to the current SPI template
included in the package.

### Project Status

### Getting Help or Reporting an Issue

To report bugs/issues/feature requests, please file an [issue](https://github.com/bcgov/bccamtrap/issues/).

### How to Contribute

If you would like to contribute, please see our [CONTRIBUTING](CONTRIBUTING.md) guidelines.

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.

### License

```
Copyright 2024 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
```
